# -*- coding: utf-8 -*-
"""final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1frE_XjO2zl8kusw4QFFo90U5z3qSXvzz

**Image Classification Blood Cells**
"""

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir ~/.kaggle

!cp kaggle.json ~/.kaggle/

!chmod 600 ~/.kaggle/kaggle.json

# Dowload dataset 
!kaggle datasets download -d paultimothymooney/blood-cells

# Commented out IPython magic to ensure Python compatibility.
import zipfile
import os
import glob 
import warnings
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten, BatchNormalization, GlobalAveragePooling2D
from tensorflow.keras.layers import Dropout
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from keras.preprocessing import image
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

# Ekstrak zip 
zip = 'blood-cells.zip'
ekstrak_zip = zipfile.ZipFile(zip, 'r')
ekstrak_zip.extractall('/dataset')
ekstrak_zip.close()

# Dataset directory
train_dir = '/dataset/dataset2-master/dataset2-master/images/TRAIN'
test_dir = '/dataset/dataset2-master/dataset2-master/images/TEST'

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    directory = train_dir,
    target_size = (224, 224),
    color_mode = 'rgb',
    class_mode = 'categorical',
    batch_size = 32,
    shuffle = True,
    seed = 42,
    subset = 'training'
)
val_generator = train_datagen.flow_from_directory(
    directory=train_dir,
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False,
    seed=42,
    subset='validation'
)

# Pembuatan Model dengan tipe Sequential

Model = Sequential(
    [
     # Activation menggunakan relu + softmax
     Conv2D(32, 3, activation = 'relu' , input_shape = (224,224,3)),
     BatchNormalization(),
     Conv2D(64, 3, activation = 'relu' ),
     MaxPooling2D(2),
     Conv2D(128, 3,  activation = 'relu' ),
     Dropout(0.5),
     GlobalAveragePooling2D(),
     Flatten(),
     Dense(256, activation = 'relu'),
     Dropout(0.5),
     Dense(4, activation='softmax')
    ]
)

Model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy',metrics = ['accuracy'])

def scheduler(epoch, lr):
  if epoch < 5:
    return lr
  else:
    return lr * tf.math.exp(-0.1)

lr_schedule = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose=1)
tb_callback = tf.keras.callbacks.TensorBoard(
    log_dir='logs', histogram_freq=0, write_graph=True, write_images=False,
    update_freq='epoch', embeddings_freq=0,
    embeddings_metadata=None
)

history = Model.fit(train_generator,
                      validation_data=val_generator,
                      callbacks=[lr_schedule, tb_callback],
                      epochs=20)

# Mengambil Nilai Accuracy 
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
# Mengambil Nilai Loss 
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

# Plot Accruracy
plt.plot(epochs, acc, 'r', label='Train accuracy')
plt.plot(epochs, val_acc, 'g', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

# Plot Loss
plt.plot(epochs, loss, 'r', label='Train loss')
plt.plot(epochs, val_loss, 'g', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.figure()
plt.show()

# Menghilangkan Warning
warnings.filterwarnings('ignore')

# Convert Model.
converter = tf.lite.TFLiteConverter.from_keras_model(Model)
tflite_model = converter.convert()

# Save the model.
with open('RPS_model.tflite', 'wb') as f:
  f.write(tflite_model)